{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORK_PROJECT_NAME = \"taxidemand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.paths import PARENT_DIR\n",
    "\n",
    "load_dotenv(PARENT_DIR / \".env\")\n",
    "\n",
    "HOPSWORK_API_KEY = os.environ[\"HOPSWORKS_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw data from 2022 to 2025\n",
      " File 2022-01 already exists\n",
      " File 2022-02 already exists\n",
      " File 2022-03 already exists\n",
      " File 2022-04 already exists\n",
      " File 2022-05 already exists\n",
      " File 2022-06 already exists\n",
      " File 2022-07 already exists\n",
      " File 2022-08 already exists\n",
      " File 2022-09 already exists\n",
      " File 2022-10 already exists\n",
      " File 2022-11 already exists\n",
      " File 2022-12 already exists\n",
      " File 2023-01 already exists\n",
      " File 2023-02 already exists\n",
      " File 2023-03 already exists\n",
      " File 2023-04 already exists\n",
      " File 2023-05 already exists\n",
      " File 2023-06 already exists\n",
      " File 2023-07 already exists\n",
      " File 2023-08 already exists\n",
      " File 2023-09 already exists\n",
      " File 2023-10 already exists\n",
      " File 2023-11 already exists\n",
      " File 2023-12 already exists\n",
      " File 2024-01 already exists\n",
      " File 2024-02 already exists\n",
      " File 2024-03 already exists\n",
      " File 2024-04 already exists\n",
      " File 2024-05 already exists\n",
      " File 2024-06 already exists\n",
      " File 2024-07 already exists\n",
      " File 2024-08 already exists\n",
      " File 2024-09 already exists\n",
      " File 2024-10 already exists\n",
      "Downloading file 2024-11\n",
      "Failed to download 2024-11\n",
      "Downloading file 2024-12\n",
      "Failed to download 2024-12\n",
      "Downloading file 2025-01\n",
      "Failed to download 2025-01\n",
      "Downloading file 2025-02\n",
      "Failed to download 2025-02\n",
      "Downloading file 2025-03\n",
      "Failed to download 2025-03\n",
      "Downloading file 2025-04\n",
      "Failed to download 2025-04\n",
      "Downloading file 2025-05\n",
      "Failed to download 2025-05\n",
      "Downloading file 2025-06\n",
      "Failed to download 2025-06\n",
      "Downloading file 2025-07\n",
      "Failed to download 2025-07\n",
      "Downloading file 2025-08\n",
      "Failed to download 2025-08\n",
      "Downloading file 2025-09\n",
      "Failed to download 2025-09\n",
      "Downloading file 2025-10\n",
      "Failed to download 2025-10\n",
      "Downloading file 2025-11\n",
      "Failed to download 2025-11\n",
      "Downloading file 2025-12\n",
      "Failed to download 2025-12\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['pickup_datetime', 'pickup_location_id'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m rides \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(from_year, to_year \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     rides_one_year \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     rides \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([rides, rides_one_year])\n",
      "File \u001b[1;32m~\\Desktop\\taxi_demand_predictor\\src\\data.py:121\u001b[0m, in \u001b[0;36mload_raw_data\u001b[1;34m(year, months)\u001b[0m\n\u001b[0;32m    117\u001b[0m     rides_one_month \u001b[38;5;241m=\u001b[39m validate_location_ids(rides_one_month)\n\u001b[0;32m    119\u001b[0m     rides \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([rides, rides_one_month])\n\u001b[1;32m--> 121\u001b[0m rides \u001b[38;5;241m=\u001b[39m \u001b[43mrides\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_location_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rides\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\src-y3nyV4sh-py3.9\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\src-y3nyV4sh-py3.9\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\src-y3nyV4sh-py3.9\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['pickup_datetime', 'pickup_location_id'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data import load_raw_data\n",
    "\n",
    "from_year = 2022\n",
    "to_year = datetime.now().year\n",
    "print(f'Downloading raw data from {from_year} to {to_year}')\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "for year in range(from_year, to_year + 1):\n",
    "    rides_one_year = load_raw_data(year)\n",
    "    rides = pd.concat([rides, rides_one_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:16<00:00, 16.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_raw_data_into_ts_data\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6532920, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from confluent_kafka import Producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIStsugDKH9AIE6Y.ImZGTncDlwIACwi6s4iY14EBNKdOs1rHsDT3MYcQDsjXt02mlZGzyTQLGBWPE6MU'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOPSWORK_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-28 18:48:04,288 INFO: Initializing external client\n",
      "2024-12-28 18:48:04,288 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2024-12-28 18:48:11,295 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207467\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(\n",
    "    project = HOPSWORK_PROJECT_NAME,\n",
    "    api_key_value = HOPSWORK_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name = FEATURE_GROUP_NAME,\n",
    "    version = FEATURE_GROUP_VERSION,\n",
    "    description = \"Time-series data at hourly frequency\",\n",
    "    primary_key = [\"pickup_location_id\",\"pickup_hour\"],\n",
    "    event_time = \"pickup_hour\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1207467/fs/1196121/fg/1394303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 6532920/6532920 | Elapsed Time: 08:59 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1207467/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-y3nyV4sh-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
